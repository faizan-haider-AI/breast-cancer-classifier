{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10564,"sourceType":"datasetVersion","datasetId":7415}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T01:36:34.690809Z","iopub.execute_input":"2025-06-17T01:36:34.691096Z","iopub.status.idle":"2025-06-17T01:36:42.636375Z","shell.execute_reply.started":"2025-06-17T01:36:34.691053Z","shell.execute_reply":"2025-06-17T01:36:42.635794Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/breast-histopathology-images'\nimage_size = 224  \nbatch_size = 32\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T01:38:11.764931Z","iopub.execute_input":"2025-06-17T01:38:11.765627Z","iopub.status.idle":"2025-06-17T01:38:11.769123Z","shell.execute_reply.started":"2025-06-17T01:38:11.765599Z","shell.execute_reply":"2025-06-17T01:38:11.768477Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":" Load All Images","metadata":{}},{"cell_type":"code","source":"import os\n\ndef load_all_images(base_path, limit=None):\n    image_paths = []\n    labels = []\n\n    for patient_id in os.listdir(base_path):\n        patient_path = os.path.join(base_path, patient_id)\n\n        \n        if not os.path.isdir(patient_path):\n            continue\n        \n        for label_folder in ['0', '1']:  # 0 = Benign, 1 = Malignant\n            label_path = os.path.join(patient_path, label_folder)\n            if not os.path.exists(label_path):\n                continue\n\n            \n            for file in os.listdir(label_path):\n                if file.endswith('.png'):\n                    image_paths.append(os.path.join(label_path, file))\n                    labels.append(int(label_folder))\n    \n    if limit:\n        image_paths = image_paths[:limit]\n        labels = labels[:limit]\n\n    return image_paths, labels\n\n\nbase_path = '/kaggle/input/breast-histopathology-images'\nimage_paths, labels = load_all_images(base_path, limit=20000)\n\nprint(\"Total images loaded:\", len(image_paths))\nprint(\"Sample image path:\", image_paths[0])\nprint(\"Label (0=Benign, 1=Malignant):\", labels[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T01:38:13.472573Z","iopub.execute_input":"2025-06-17T01:38:13.473038Z","iopub.status.idle":"2025-06-17T01:38:28.770972Z","shell.execute_reply.started":"2025-06-17T01:38:13.473014Z","shell.execute_reply":"2025-06-17T01:38:28.770214Z"}},"outputs":[{"name":"stdout","text":"Total images loaded: 20000\nSample image path: /kaggle/input/breast-histopathology-images/10295/0/10295_idx5_x1351_y1101_class0.png\nLabel (0=Benign, 1=Malignant): 0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Image Pre-processing and and Training","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n# Resize images to 64x64\nimage_size = 64\nbatch_size = 32\n\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n\nclass HistopathologyDataset(Dataset):\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        label = self.labels[idx]\n        return image, label\n\n# Split into train and validation\nfrom sklearn.model_selection import train_test_split\n\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(\n    image_paths, labels, test_size=0.2, stratify=labels, random_state=42)\n\ntrain_dataset = HistopathologyDataset(train_paths, train_labels, transform=transform)\nval_dataset = HistopathologyDataset(val_paths, val_labels, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T01:40:02.182324Z","iopub.execute_input":"2025-06-17T01:40:02.182835Z","iopub.status.idle":"2025-06-17T01:40:02.209111Z","shell.execute_reply.started":"2025-06-17T01:40:02.182808Z","shell.execute_reply":"2025-06-17T01:40:02.208376Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n\nclass EnhancedCNN(nn.Module):\n    def __init__(self):\n        super(EnhancedCNN, self).__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n            nn.Flatten(),\n            nn.Linear(128 * (image_size // 8) * (image_size // 8), 128), nn.ReLU(),\n            nn.Dropout(0.5),  # Dropout layer with 50% probability\n            nn.Linear(128, 2)  # 2 classes (Benign, Malignant)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n# Assuming image_size is defined earlier, otherwise set it\nimage_size = 64  # Adjust as per your input image size\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Initialize and move model to device\nmodel = EnhancedCNN().to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T01:40:04.743306Z","iopub.execute_input":"2025-06-17T01:40:04.744178Z","iopub.status.idle":"2025-06-17T01:40:05.019007Z","shell.execute_reply.started":"2025-06-17T01:40:04.744154Z","shell.execute_reply":"2025-06-17T01:40:05.018483Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Datasets Transformation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\n\n\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(\n    image_paths, labels, test_size=0.2, stratify=labels, random_state=42)\n\n\ntrain_dataset = HistopathologyDataset(train_paths, train_labels, transform=transform)\nval_dataset = HistopathologyDataset(val_paths, val_labels, transform=transform)\n\n# Create DataLoader for train and validation sets\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T01:40:07.733413Z","iopub.execute_input":"2025-06-17T01:40:07.733952Z","iopub.status.idle":"2025-06-17T01:40:07.754632Z","shell.execute_reply.started":"2025-06-17T01:40:07.733930Z","shell.execute_reply":"2025-06-17T01:40:07.754126Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Training ","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\n\n# Initialize optimizer and loss function\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\n# Learning rate scheduler\nscheduler = StepLR(optimizer, step_size=5, gamma=0.7)\n\n# Training function\ndef train(model, loader):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n        # Accuracy calculation\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    \n    accuracy = correct / total\n    return total_loss / len(loader), accuracy\n\n# Validation function\ndef validate(model, loader):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    \n    accuracy = correct / total\n    return accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T01:40:14.053370Z","iopub.execute_input":"2025-06-17T01:40:14.054069Z","iopub.status.idle":"2025-06-17T01:40:14.060916Z","shell.execute_reply.started":"2025-06-17T01:40:14.054043Z","shell.execute_reply":"2025-06-17T01:40:14.060226Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Epochs","metadata":{}},{"cell_type":"code","source":"num_epochs = 20  # You can increase this for better training\n\nfor epoch in range(num_epochs):\n    # Train the model\n    train_loss, train_accuracy = train(model, train_loader)\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n    \n    # Validate the model\n    val_accuracy = validate(model, val_loader)\n    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Accuracy: {val_accuracy:.4f}\")\n    \n    # Update the learning rate\n    scheduler.step()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T01:40:18.831840Z","iopub.execute_input":"2025-06-17T01:40:18.832447Z","iopub.status.idle":"2025-06-17T01:50:54.836986Z","shell.execute_reply.started":"2025-06-17T01:40:18.832422Z","shell.execute_reply":"2025-06-17T01:50:54.836383Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20, Train Loss: 0.3816, Train Accuracy: 0.8336\nEpoch 1/20, Validation Accuracy: 0.8615\nEpoch 2/20, Train Loss: 0.3280, Train Accuracy: 0.8619\nEpoch 2/20, Validation Accuracy: 0.8327\nEpoch 3/20, Train Loss: 0.3047, Train Accuracy: 0.8729\nEpoch 3/20, Validation Accuracy: 0.8842\nEpoch 4/20, Train Loss: 0.2890, Train Accuracy: 0.8788\nEpoch 4/20, Validation Accuracy: 0.8898\nEpoch 5/20, Train Loss: 0.2728, Train Accuracy: 0.8874\nEpoch 5/20, Validation Accuracy: 0.8802\nEpoch 6/20, Train Loss: 0.2443, Train Accuracy: 0.8972\nEpoch 6/20, Validation Accuracy: 0.8922\nEpoch 7/20, Train Loss: 0.2294, Train Accuracy: 0.9036\nEpoch 7/20, Validation Accuracy: 0.8875\nEpoch 8/20, Train Loss: 0.2160, Train Accuracy: 0.9102\nEpoch 8/20, Validation Accuracy: 0.8855\nEpoch 9/20, Train Loss: 0.1984, Train Accuracy: 0.9175\nEpoch 9/20, Validation Accuracy: 0.8928\nEpoch 10/20, Train Loss: 0.1749, Train Accuracy: 0.9274\nEpoch 10/20, Validation Accuracy: 0.8900\nEpoch 11/20, Train Loss: 0.1481, Train Accuracy: 0.9385\nEpoch 11/20, Validation Accuracy: 0.8945\nEpoch 12/20, Train Loss: 0.1295, Train Accuracy: 0.9461\nEpoch 12/20, Validation Accuracy: 0.8915\nEpoch 13/20, Train Loss: 0.1111, Train Accuracy: 0.9544\nEpoch 13/20, Validation Accuracy: 0.8850\nEpoch 14/20, Train Loss: 0.0973, Train Accuracy: 0.9596\nEpoch 14/20, Validation Accuracy: 0.8908\nEpoch 15/20, Train Loss: 0.0834, Train Accuracy: 0.9665\nEpoch 15/20, Validation Accuracy: 0.8930\nEpoch 16/20, Train Loss: 0.0625, Train Accuracy: 0.9749\nEpoch 16/20, Validation Accuracy: 0.8908\nEpoch 17/20, Train Loss: 0.0550, Train Accuracy: 0.9779\nEpoch 17/20, Validation Accuracy: 0.8868\nEpoch 18/20, Train Loss: 0.0472, Train Accuracy: 0.9821\nEpoch 18/20, Validation Accuracy: 0.8945\nEpoch 19/20, Train Loss: 0.0467, Train Accuracy: 0.9824\nEpoch 19/20, Validation Accuracy: 0.8930\nEpoch 20/20, Train Loss: 0.0396, Train Accuracy: 0.9858\nEpoch 20/20, Validation Accuracy: 0.8905\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Prevent Overfitting","metadata":{}},{"cell_type":"code","source":"# Evaluate the model on the validation set after training\nfinal_accuracy = validate(model, val_loader)\nprint(f\"Final Validation Accuracy: {final_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T01:52:58.999452Z","iopub.execute_input":"2025-06-17T01:52:59.000066Z","iopub.status.idle":"2025-06-17T01:53:03.940649Z","shell.execute_reply.started":"2025-06-17T01:52:59.000043Z","shell.execute_reply":"2025-06-17T01:53:03.940009Z"}},"outputs":[{"name":"stdout","text":"Final Validation Accuracy: 0.8905\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"torch.save(model.state_dict(), 'breast_cancer_model.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T01:53:08.159635Z","iopub.execute_input":"2025-06-17T01:53:08.160308Z","iopub.status.idle":"2025-06-17T01:53:08.173897Z","shell.execute_reply.started":"2025-06-17T01:53:08.160286Z","shell.execute_reply":"2025-06-17T01:53:08.173338Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}